{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle Readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Chargement du dataset de training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importer les modules et préparer le chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "pathTrainingDataset = \"C:/Users/user/Documents/Code/Machine-Learning/my_dataset/train\"\n",
    "\n",
    "CATEGORIES = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"]\n",
    "\n",
    "IMSIZE = 50\n",
    "\n",
    "training_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Générer traning_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(pathTrainingDataset, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for im in os.listdir(path):\n",
    "            img_array = cv2.imread(os.path.join(path, im), cv2.IMREAD_GRAYSCALE)\n",
    "            img_array = cv2.resize(img_array, (IMSIZE, IMSIZE))\n",
    "            training_data.append([img_array, class_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changer l'ordre de la liste training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparer les labels et les features ainsi que préparer les features pour le training du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for feature, label in training_data:\n",
    "    X.append(feature)\n",
    "    Y.append(label)  \n",
    "\n",
    "X = np.array(X).reshape(-1, IMSIZE, IMSIZE, 1)\n",
    "\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Entrainement du modèle</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importer les couches Dense, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.activations import relu, softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer le modèle avec les différentes couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(4,4), input_shape=X.shape[1:], activation=relu))\n",
    "model.add(MaxPooling2D(pool_size=(4,4)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(4,4), activation=relu))\n",
    "model.add(MaxPooling2D(pool_size=((4,4))))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(500, activation=relu))\n",
    "model.add(Dense(500, activation=relu))\n",
    "model.add(Dense(500, activation=relu))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(26, activation=softmax))\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                 metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainer le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1059 samples, validate on 118 samples\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 12s 12ms/step - loss: 3.2383 - acc: 0.0453 - val_loss: 3.1460 - val_acc: 0.0763\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 11s 11ms/step - loss: 2.4686 - acc: 0.2682 - val_loss: 1.8482 - val_acc: 0.3475\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 12s 11ms/step - loss: 1.2278 - acc: 0.6232 - val_loss: 0.9516 - val_acc: 0.6780\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 11s 11ms/step - loss: 0.6792 - acc: 0.7828 - val_loss: 0.6805 - val_acc: 0.7627\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 11s 11ms/step - loss: 0.4124 - acc: 0.8697 - val_loss: 0.6765 - val_acc: 0.8220\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 11s 11ms/step - loss: 0.2975 - acc: 0.9122 - val_loss: 0.6203 - val_acc: 0.8051\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 12s 11ms/step - loss: 0.2051 - acc: 0.9367 - val_loss: 0.5578 - val_acc: 0.8136\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 13s 13ms/step - loss: 0.1973 - acc: 0.9348 - val_loss: 0.6159 - val_acc: 0.7881\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 12s 11ms/step - loss: 0.1176 - acc: 0.9613 - val_loss: 1.0460 - val_acc: 0.7966\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 12s 11ms/step - loss: 0.1418 - acc: 0.9528 - val_loss: 0.4697 - val_acc: 0.8729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e2adb73da0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=32, epochs=10, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"readable-model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
