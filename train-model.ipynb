{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle Readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Chargement du dataset de training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importer les modules et préparer le chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "pathTrainingDataset = \"C:/Users/user/Documents/Code/Machine-Learning/my_dataset/train\"\n",
    "\n",
    "CATEGORIES = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"]\n",
    "\n",
    "IMSIZE = 50\n",
    "\n",
    "training_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Générer traning_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(pathTrainingDataset, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for im in os.listdir(path):\n",
    "            img_array = cv2.imread(os.path.join(path, im), cv2.IMREAD_GRAYSCALE)\n",
    "            img_array = cv2.resize(img_array, (IMSIZE, IMSIZE))\n",
    "            training_data.append([img_array, class_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changer l'ordre de la liste training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparer les labels et les features ainsi que préparer les features pour le training du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for feature, label in training_data:\n",
    "    X.append(feature)\n",
    "    Y.append(label)  \n",
    "\n",
    "X = np.array(X).reshape(-1, IMSIZE, IMSIZE, 1)\n",
    "\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Entrainement du modèle</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importer les couches Dense, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.activations import relu, softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer le modèle avec les différentes couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(4,4), input_shape=X.shape[1:], activation=relu))\n",
    "model.add(MaxPooling2D(pool_size=(4,4)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(4,4), activation=relu))\n",
    "model.add(MaxPooling2D(pool_size=((4,4))))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(500, activation=relu))\n",
    "model.add(Dense(500, activation=relu))\n",
    "model.add(Dense(500, activation=relu))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(26, activation=softmax))\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                 metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainer le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 868 samples, validate on 97 samples\n",
      "Epoch 1/10\n",
      "868/868 [==============================] - 11s 12ms/step - loss: 3.2229 - acc: 0.0772 - val_loss: 3.0010 - val_acc: 0.1340\n",
      "Epoch 2/10\n",
      "868/868 [==============================] - 10s 11ms/step - loss: 2.1423 - acc: 0.3548 - val_loss: 2.0584 - val_acc: 0.3299\n",
      "Epoch 3/10\n",
      "868/868 [==============================] - 9s 11ms/step - loss: 1.1675 - acc: 0.6429 - val_loss: 0.9191 - val_acc: 0.6598\n",
      "Epoch 4/10\n",
      "868/868 [==============================] - 9s 11ms/step - loss: 0.7055 - acc: 0.7834 - val_loss: 0.5602 - val_acc: 0.8247\n",
      "Epoch 5/10\n",
      "868/868 [==============================] - 9s 11ms/step - loss: 0.4955 - acc: 0.8560 - val_loss: 0.4970 - val_acc: 0.8454\n",
      "Epoch 6/10\n",
      "868/868 [==============================] - 9s 11ms/step - loss: 0.3334 - acc: 0.8906 - val_loss: 0.4128 - val_acc: 0.8763\n",
      "Epoch 7/10\n",
      "868/868 [==============================] - 9s 11ms/step - loss: 0.2616 - acc: 0.9194 - val_loss: 0.4933 - val_acc: 0.8660\n",
      "Epoch 8/10\n",
      "868/868 [==============================] - 9s 11ms/step - loss: 0.1339 - acc: 0.9562 - val_loss: 0.3617 - val_acc: 0.9072\n",
      "Epoch 9/10\n",
      "868/868 [==============================] - 9s 11ms/step - loss: 0.0767 - acc: 0.9781 - val_loss: 0.4024 - val_acc: 0.8969\n",
      "Epoch 10/10\n",
      "868/868 [==============================] - 9s 11ms/step - loss: 0.0804 - acc: 0.9747 - val_loss: 0.4714 - val_acc: 0.8763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e2a3ab64a8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=32, epochs=10, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"readable-model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
